{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db1edbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exx/miniconda3/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "from modeling_dream.modeling_dream import DreamModel\n",
    "from modeling_dream.tokenization_dream import DreamTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e03b043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda (dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "def select_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    mps_backend = getattr(torch.backends, \"mps\", None)\n",
    "    if mps_backend is not None and mps_backend.is_available():\n",
    "        return \"mps\"\n",
    "    return \"cpu\"\n",
    "# end\n",
    "\n",
    "# --- Model Loading ---\n",
    "model_path = \"Dream-org/Dream-v0-Instruct-7B\"\n",
    "device = select_device()\n",
    "dtype_by_device = {\n",
    "    \"cuda\": torch.bfloat16,\n",
    "    \"mps\": torch.float16,\n",
    "    \"cpu\": torch.float32,\n",
    "}\n",
    "dtype = dtype_by_device[device]\n",
    "print(f\"Using device: {device} (dtype={dtype})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afa41754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.55it/s]\n",
      "/home/exx/miniconda3/lib/python3.13/site-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/exx/miniconda3/lib/python3.13/site-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a man named Joey who lived in a small town. He was a kind and loving person who had a lot of friends. One day, Joey met a beautiful woman named Rachel. They fell in love and decided to get married. However, there was a problem. Joey's parents didn't like Rachel, and they didn't want their son to marry her. Joey was heartbroken, but he didn't give up. He tried to convince his parents that Rachel was the one for him, but they wouldn't listen. Joey and Rachel decided to move in together, and they worked hard to make it work. They had arguments and moments of joy, but they didn't want to give up on each other. One day, Joey's parents came to visit, and they met Rachel. They were surprised by how wonderful she was, and they decided to support their son's decision. Finally, Joey and Rachel got married, and they lived happily ever after.\n",
      "------\n",
      "Janet's ducks lay 16 eggs per day.\n",
      "She eats 3 eggs for breakfast and bakes 4 eggs for muffins, so she uses a total of 3 + 4 = 7 eggs per day.\n",
      "Therefore, she sells 16 - 7 = 9 eggs per day.\n",
      "She sells each egg for $2, so she makes 9 * $2 = $18 per day at the farmers' market.\n",
      "#### 18\n",
      "The answer is: 18\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DreamTokenizer.from_pretrained(\n",
    "    model_path,\n",
    "    trust_remote_code=True,\n",
    "    padding_side='left'\n",
    ")\n",
    "\n",
    "model = DreamModel.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=dtype,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# set left padding\n",
    "model = model.to(device).eval()\n",
    "\n",
    "messages = [[\n",
    "    {\"role\": \"user\", \"content\": \"Write a story that ends with 'Finally, Joey and Rachel get married.'\"}\n",
    "],\n",
    "[\n",
    "    {\"role\": \"user\", \"content\": \"Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\"}\n",
    "]]\n",
    "# set padding=True\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages, return_tensors=\"pt\", return_dict=True, add_generation_prompt=True, padding=True\n",
    ")\n",
    "input_ids = inputs.input_ids.to(device)\n",
    "attention_mask = inputs.attention_mask.to(device)\n",
    "\n",
    "output = model.diffusion_generate(\n",
    "    input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_new_tokens=256,\n",
    "    output_history=True,\n",
    "    return_dict_in_generate=True,\n",
    "    steps=256,\n",
    "    temperature=0.2,\n",
    "    top_p=0.95,\n",
    "    alg=\"entropy\",\n",
    "    alg_temp=0.,\n",
    ")\n",
    "generations = [\n",
    "    tokenizer.decode(g[len(p) :].tolist())\n",
    "    for p, g in zip(input_ids, output.sequences)\n",
    "]\n",
    "\n",
    "print(generations[0].split(tokenizer.eos_token)[0])\n",
    "print(\"------\")\n",
    "print(generations[1].split(tokenizer.eos_token)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f8b3a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to inspect: /home/exx/.cache/huggingface/modules/transformers_modules/Dream-org/Dream-v0-Instruct-7B/05334cb9faaf763692dcf9d8737c642be2b2a6ae/modeling_dream.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from jinyu_utils.jinyu_inspect import jinyu_inspect_file\n",
    "jinyu_inspect_file(model.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d602aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers_modules.Dream-org.Dream-v0-Instruct-7B.05334cb9faaf763692dcf9d8737c642be2b2a6ae.modeling_dream.DreamModel"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
